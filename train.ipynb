{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pipeline import Pipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transforms import pad_token\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, token_idx, idx_token = Pipeline.load(\"10k_common\").data\n",
    "ratings = Pipeline.load(\"ratings\").data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, vocab_size, pad_idx):\n",
    "        # RNN Accepts the following hyperparams:\n",
    "        # emb_size: Embedding Size\n",
    "        # hidden_size: Hidden Size of layer in RNN\n",
    "        # num_layers: number of layers in RNN\n",
    "        # vocab_size: vocabulary size\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=pad_idx)\n",
    "        self.rnn = nn.RNN(emb_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Function initializes the activation of recurrent neural net at timestep 0\n",
    "        # Needs to be in format (num_layers, batch_size, hidden_size)\n",
    "        hidden = torch.randn(self.num_layers, batch_size, self.hidden_size)\n",
    "\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # reset hidden state\n",
    "\n",
    "        batch_size, seq_len = x.size()\n",
    "\n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # get embedding of characters\n",
    "        embed = self.embedding(x)\n",
    "        # pack padded sequence\n",
    "        embed = torch.nn.utils.rnn.pack_padded_sequence(embed, lengths.numpy(), batch_first=True)\n",
    "        # fprop though RNN\n",
    "        rnn_out, self.hidden = self.rnn(embed, self.hidden)\n",
    "        # undo packing\n",
    "        rnn_out, _ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out, batch_first=True)\n",
    "        # sum hidden activations of RNN across time\n",
    "        rnn_out = torch.sum(rnn_out, dim=1)\n",
    "\n",
    "        logits = self.linear(rnn_out)\n",
    "        return logits\n",
    "\n",
    "class ScriptsDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return (self.data[key], self.labels[key])\n",
    "    \n",
    "    def get_loader(self, batch_size = 32):\n",
    "        return DataLoader(\n",
    "            dataset = self,\n",
    "            batch_size = batch_size,\n",
    "            collate_fn = self.collate,\n",
    "            shuffle = True\n",
    "        )\n",
    "    \n",
    "    def collate(self, batch):\n",
    "        data_list = []\n",
    "        label_list = []\n",
    "        length_list = []\n",
    "\n",
    "        for datum in batch:\n",
    "            label_list.append(datum[1])\n",
    "            length_list.append(len(datum[0]))\n",
    "            data_list.append(torch.tensor(datum[0]))\n",
    "            \n",
    "        data_list = pad_sequence(data_list, batch_first = True)\n",
    "        sorted_length_list, sorted_idxs = torch.sort(torch.tensor(length_list), descending = True)\n",
    "        data_list = data_list[sorted_idxs]\n",
    "        label_list = torch.tensor(label_list)[sorted_idxs]\n",
    "        \n",
    "        return data_list, sorted_length_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in tqdm(loader, desc = \"Validation Batches\", unit = \"batch\"):\n",
    "        data_batch, lengths_batch, label_batch = data, lengths, labels\n",
    "        predicted = model(data_batch, lengths_batch)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += torch.mean((predicted - labels) ** 2)\n",
    "    return (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, ratings, test_size=0.15, random_state=42)\n",
    "X_train, X_test = X_train.reset_index(drop=True), X_test.reset_index(drop=True)\n",
    "\n",
    "train_loader = ScriptsDataset(X_train, y_train).get_loader(batch_size = 5)\n",
    "val_loader = ScriptsDataset(X_test, y_test).get_loader(batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(emb_size=100, hidden_size=200, num_layers=1, vocab_size=len(idx_token), pad_idx = token_idx[pad_token])\n",
    "\n",
    "learning_rate = .1\n",
    "num_epochs = 2 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/2 [00:00<?, ?epoch/s]\n",
      "Batches:   0%|          | 0/704 [00:00<?, ?batch/s]\u001b[A\n",
      "Batches:   0%|          | 1/704 [00:05<1:09:29,  5.93s/batch]\u001b[A\n",
      "Batches:   0%|          | 2/704 [00:12<1:12:14,  6.17s/batch]\u001b[A\n",
      "Batches:   0%|          | 3/704 [00:17<1:07:34,  5.78s/batch]\u001b[A\n",
      "Batches:   1%|          | 4/704 [00:24<1:13:12,  6.27s/batch]\u001b[A\n",
      "Batches:   1%|          | 5/704 [00:29<1:06:01,  5.67s/batch]\u001b[A\n",
      "Batches:   1%|          | 6/704 [00:38<1:19:52,  6.87s/batch]\u001b[A\n",
      "Batches:   1%|          | 7/704 [00:42<1:09:38,  6.00s/batch]\u001b[A\n",
      "Batches:   1%|          | 8/704 [00:47<1:06:32,  5.74s/batch]\u001b[A\n",
      "Batches:   1%|▏         | 9/704 [00:52<1:01:49,  5.34s/batch]\u001b[A\n",
      "Batches:   1%|▏         | 10/704 [00:58<1:04:09,  5.55s/batch]\u001b[A\n",
      "Batches:   2%|▏         | 11/704 [01:02<59:28,  5.15s/batch]  \u001b[A\n",
      "Batches:   2%|▏         | 12/704 [01:09<1:06:15,  5.74s/batch]\u001b[A\n",
      "Batches:   2%|▏         | 13/704 [01:14<1:03:18,  5.50s/batch]\u001b[A\n",
      "Batches:   2%|▏         | 14/704 [01:18<57:24,  4.99s/batch]  \u001b[A\n",
      "Batches:   2%|▏         | 15/704 [01:24<59:14,  5.16s/batch]\u001b[A\n",
      "Batches:   2%|▏         | 16/704 [01:32<1:11:19,  6.22s/batch]\u001b[A\n",
      "Batches:   2%|▏         | 17/704 [01:37<1:06:22,  5.80s/batch]\u001b[A\n",
      "Batches:   3%|▎         | 18/704 [01:42<1:02:58,  5.51s/batch]\u001b[A\n",
      "Batches:   3%|▎         | 19/704 [01:53<1:23:05,  7.28s/batch]\u001b[A\n",
      "Batches:   3%|▎         | 20/704 [01:58<1:15:09,  6.59s/batch]\u001b[A\n",
      "Batches:   3%|▎         | 21/704 [02:03<1:09:18,  6.09s/batch]\u001b[A\n",
      "Batches:   3%|▎         | 22/704 [02:14<1:23:59,  7.39s/batch]\u001b[A\n",
      "Batches:   3%|▎         | 23/704 [02:19<1:18:28,  6.91s/batch]\u001b[A\n",
      "Batches:   3%|▎         | 24/704 [02:24<1:10:53,  6.26s/batch]\u001b[A\n",
      "Batches:   4%|▎         | 25/704 [02:28<1:03:06,  5.58s/batch]\u001b[A\n",
      "Batches:   4%|▎         | 26/704 [02:33<59:57,  5.31s/batch]  \u001b[A\n",
      "Batches:   4%|▍         | 27/704 [02:43<1:16:33,  6.78s/batch]\u001b[A\n",
      "Batches:   4%|▍         | 28/704 [02:52<1:22:48,  7.35s/batch]\u001b[A\n",
      "Batches:   4%|▍         | 29/704 [02:57<1:14:24,  6.61s/batch]\u001b[A\n",
      "Batches:   4%|▍         | 30/704 [03:03<1:14:15,  6.61s/batch]\u001b[A\n",
      "Batches:   4%|▍         | 31/704 [03:08<1:07:47,  6.04s/batch]\u001b[A\n",
      "Batches:   5%|▍         | 32/704 [03:14<1:08:03,  6.08s/batch]\u001b[A\n",
      "Batches:   5%|▍         | 33/704 [03:19<1:04:15,  5.75s/batch]\u001b[A\n",
      "Batches:   5%|▍         | 34/704 [03:24<1:00:35,  5.43s/batch]\u001b[A\n",
      "Batches:   5%|▍         | 35/704 [03:30<1:04:17,  5.77s/batch]\u001b[A\n",
      "Batches:   5%|▌         | 36/704 [03:35<1:01:47,  5.55s/batch]\u001b[A\n",
      "Batches:   5%|▌         | 37/704 [03:41<1:01:54,  5.57s/batch]\u001b[A\n",
      "Batches:   5%|▌         | 38/704 [03:50<1:13:53,  6.66s/batch]\u001b[A\n",
      "Batches:   6%|▌         | 39/704 [03:55<1:07:01,  6.05s/batch]\u001b[A\n",
      "Batches:   6%|▌         | 40/704 [04:00<1:05:21,  5.91s/batch]\u001b[A\n",
      "Batches:   6%|▌         | 41/704 [04:05<1:01:52,  5.60s/batch]\u001b[A\n",
      "Batches:   6%|▌         | 42/704 [04:10<59:26,  5.39s/batch]  \u001b[A\n",
      "Batches:   6%|▌         | 43/704 [04:16<1:01:59,  5.63s/batch]\u001b[A\n",
      "Batches:   6%|▋         | 44/704 [04:29<1:24:48,  7.71s/batch]\u001b[A\n",
      "Batches:   6%|▋         | 45/704 [04:35<1:18:22,  7.14s/batch]\u001b[A\n",
      "Batches:   7%|▋         | 46/704 [04:40<1:10:49,  6.46s/batch]\u001b[A\n",
      "Batches:   7%|▋         | 47/704 [04:46<1:09:57,  6.39s/batch]\u001b[A\n",
      "Batches:   7%|▋         | 48/704 [04:51<1:06:21,  6.07s/batch]\u001b[A\n",
      "Batches:   7%|▋         | 49/704 [04:56<1:01:13,  5.61s/batch]\u001b[A\n",
      "Batches:   7%|▋         | 50/704 [05:06<1:15:57,  6.97s/batch]\u001b[A\n",
      "Batches:   7%|▋         | 51/704 [05:11<1:08:25,  6.29s/batch]\u001b[A\n",
      "Batches:   7%|▋         | 52/704 [05:17<1:09:28,  6.39s/batch]\u001b[A\n",
      "Batches:   8%|▊         | 53/704 [05:30<1:30:44,  8.36s/batch]\u001b[A\n",
      "Batches:   8%|▊         | 54/704 [05:37<1:25:19,  7.88s/batch]\u001b[A\n",
      "Batches:   8%|▊         | 55/704 [05:45<1:27:15,  8.07s/batch]\u001b[A\n",
      "Batches:   8%|▊         | 56/704 [05:49<1:13:11,  6.78s/batch]\u001b[A\n",
      "Batches:   8%|▊         | 57/704 [05:55<1:10:26,  6.53s/batch]\u001b[A\n",
      "Batches:   8%|▊         | 58/704 [06:00<1:04:20,  5.98s/batch]\u001b[A\n",
      "Batches:   8%|▊         | 59/704 [06:05<1:01:16,  5.70s/batch]\u001b[A\n",
      "Batches:   9%|▊         | 60/704 [06:09<56:22,  5.25s/batch]  \u001b[A\n",
      "Batches:   9%|▊         | 61/704 [06:13<52:42,  4.92s/batch]\u001b[A\n",
      "Batches:   9%|▉         | 62/704 [06:20<57:53,  5.41s/batch]\u001b[A\n",
      "Batches:   9%|▉         | 63/704 [06:32<1:19:52,  7.48s/batch]\u001b[A\n",
      "Batches:   9%|▉         | 64/704 [06:40<1:22:56,  7.78s/batch]\u001b[A\n",
      "Batches:   9%|▉         | 65/704 [06:47<1:18:46,  7.40s/batch]\u001b[A\n",
      "Batches:   9%|▉         | 66/704 [06:51<1:08:41,  6.46s/batch]\u001b[A\n",
      "Batches:  10%|▉         | 67/704 [07:02<1:21:19,  7.66s/batch]\u001b[A\n",
      "Batches:  10%|▉         | 68/704 [07:10<1:22:48,  7.81s/batch]\u001b[A\n",
      "Batches:  10%|▉         | 69/704 [07:18<1:22:16,  7.77s/batch]\u001b[A\n",
      "Batches:  10%|▉         | 70/704 [07:23<1:15:28,  7.14s/batch]\u001b[A\n",
      "Batches:  10%|█         | 71/704 [07:27<1:05:34,  6.22s/batch]\u001b[A\n",
      "Batches:  10%|█         | 72/704 [07:39<1:24:02,  7.98s/batch]\u001b[A\n",
      "Batches:  10%|█         | 73/704 [07:46<1:17:59,  7.42s/batch]\u001b[A\n",
      "Batches:  11%|█         | 74/704 [07:50<1:08:34,  6.53s/batch]\u001b[A\n",
      "Batches:  11%|█         | 75/704 [08:00<1:18:16,  7.47s/batch]\u001b[A\n",
      "Batches:  11%|█         | 76/704 [08:07<1:17:11,  7.37s/batch]\u001b[A\n",
      "Batches:  11%|█         | 77/704 [08:15<1:19:42,  7.63s/batch]\u001b[A\n",
      "Batches:  11%|█         | 78/704 [08:21<1:15:59,  7.28s/batch]\u001b[A\n",
      "Batches:  11%|█         | 79/704 [08:25<1:05:34,  6.30s/batch]\u001b[A\n",
      "Batches:  11%|█▏        | 80/704 [08:30<59:40,  5.74s/batch]  \u001b[A\n",
      "Batches:  12%|█▏        | 81/704 [08:36<1:00:01,  5.78s/batch]\u001b[A\n",
      "Batches:  12%|█▏        | 82/704 [08:46<1:12:18,  6.97s/batch]\u001b[A\n",
      "Batches:  12%|█▏        | 83/704 [08:51<1:07:31,  6.52s/batch]\u001b[A\n",
      "Batches:  12%|█▏        | 84/704 [08:56<1:01:04,  5.91s/batch]\u001b[A\n",
      "Batches:  12%|█▏        | 85/704 [09:02<1:02:14,  6.03s/batch]\u001b[A\n",
      "Batches:  12%|█▏        | 86/704 [09:07<59:38,  5.79s/batch]  \u001b[A\n",
      "Batches:  12%|█▏        | 87/704 [09:12<57:20,  5.58s/batch]\u001b[A\n",
      "Batches:  12%|█▎        | 88/704 [09:18<58:42,  5.72s/batch]\u001b[A\n",
      "Batches:  13%|█▎        | 89/704 [09:32<1:22:53,  8.09s/batch]\u001b[A\n",
      "Batches:  13%|█▎        | 90/704 [09:44<1:35:38,  9.35s/batch]\u001b[A\n",
      "Batches:  13%|█▎        | 91/704 [09:48<1:18:50,  7.72s/batch]\u001b[A\n",
      "Batches:  13%|█▎        | 92/704 [09:53<1:10:44,  6.94s/batch]\u001b[A\n",
      "Batches:  13%|█▎        | 93/704 [09:59<1:06:14,  6.50s/batch]\u001b[A\n",
      "Batches:  13%|█▎        | 94/704 [10:07<1:12:25,  7.12s/batch]\u001b[A\n",
      "Batches:  13%|█▎        | 95/704 [10:12<1:04:38,  6.37s/batch]\u001b[A\n",
      "Batches:  14%|█▎        | 96/704 [10:18<1:03:05,  6.23s/batch]\u001b[A\n",
      "Batches:  14%|█▍        | 97/704 [10:27<1:13:02,  7.22s/batch]\u001b[A\n",
      "Batches:  14%|█▍        | 98/704 [10:33<1:08:12,  6.75s/batch]\u001b[A\n",
      "Batches:  14%|█▍        | 99/704 [10:39<1:07:40,  6.71s/batch]\u001b[A\n",
      "Batches:  14%|█▍        | 100/704 [10:47<1:08:54,  6.84s/batch]\u001b[A\n",
      "\n",
      "Validation Batches:   0%|          | 0/125 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   1%|          | 1/125 [00:00<00:46,  2.69batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   2%|▏         | 2/125 [00:00<00:43,  2.84batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   2%|▏         | 3/125 [00:01<00:42,  2.84batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   3%|▎         | 4/125 [00:01<00:42,  2.83batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   4%|▍         | 5/125 [00:01<00:39,  3.06batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   5%|▍         | 6/125 [00:01<00:37,  3.18batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   6%|▌         | 7/125 [00:02<00:35,  3.32batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   6%|▋         | 8/125 [00:02<00:37,  3.12batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   7%|▋         | 9/125 [00:02<00:37,  3.11batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   8%|▊         | 10/125 [00:03<00:36,  3.13batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:   9%|▉         | 11/125 [00:03<00:36,  3.09batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  10%|▉         | 12/125 [00:03<00:33,  3.37batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  10%|█         | 13/125 [00:04<00:32,  3.40batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  11%|█         | 14/125 [00:04<00:31,  3.47batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  12%|█▏        | 15/125 [00:04<00:29,  3.67batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  13%|█▎        | 16/125 [00:04<00:30,  3.63batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  14%|█▎        | 17/125 [00:05<00:30,  3.60batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  14%|█▍        | 18/125 [00:05<00:29,  3.65batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  15%|█▌        | 19/125 [00:05<00:30,  3.50batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  16%|█▌        | 20/125 [00:06<00:29,  3.50batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  17%|█▋        | 21/125 [00:06<00:30,  3.40batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  18%|█▊        | 22/125 [00:06<00:29,  3.48batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  18%|█▊        | 23/125 [00:06<00:31,  3.28batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  19%|█▉        | 24/125 [00:07<00:28,  3.49batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  20%|██        | 25/125 [00:07<00:30,  3.23batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  21%|██        | 26/125 [00:07<00:31,  3.10batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  22%|██▏       | 27/125 [00:08<00:29,  3.37batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  22%|██▏       | 28/125 [00:08<00:28,  3.40batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  23%|██▎       | 29/125 [00:08<00:28,  3.38batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  24%|██▍       | 30/125 [00:09<00:28,  3.37batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  25%|██▍       | 31/125 [00:09<00:26,  3.50batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  26%|██▌       | 32/125 [00:09<00:26,  3.56batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  26%|██▋       | 33/125 [00:09<00:28,  3.27batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  27%|██▋       | 34/125 [00:10<00:28,  3.17batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  28%|██▊       | 35/125 [00:10<00:29,  3.07batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  29%|██▉       | 36/125 [00:10<00:27,  3.24batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  30%|██▉       | 37/125 [00:11<00:26,  3.35batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  30%|███       | 38/125 [00:11<00:24,  3.53batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  31%|███       | 39/125 [00:11<00:23,  3.66batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  32%|███▏      | 40/125 [00:12<00:25,  3.31batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  33%|███▎      | 41/125 [00:12<00:24,  3.42batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  34%|███▎      | 42/125 [00:12<00:23,  3.57batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  34%|███▍      | 43/125 [00:12<00:26,  3.10batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  35%|███▌      | 44/125 [00:13<00:25,  3.19batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  36%|███▌      | 45/125 [00:13<00:24,  3.31batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  37%|███▋      | 46/125 [00:13<00:23,  3.35batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  38%|███▊      | 47/125 [00:14<00:23,  3.26batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  38%|███▊      | 48/125 [00:14<00:24,  3.20batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  39%|███▉      | 49/125 [00:14<00:24,  3.09batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  40%|████      | 50/125 [00:15<00:24,  3.09batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  41%|████      | 51/125 [00:15<00:22,  3.24batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  42%|████▏     | 52/125 [00:15<00:21,  3.38batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  42%|████▏     | 53/125 [00:15<00:21,  3.40batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  43%|████▎     | 54/125 [00:16<00:19,  3.63batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  44%|████▍     | 55/125 [00:16<00:19,  3.60batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  45%|████▍     | 56/125 [00:16<00:19,  3.58batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  46%|████▌     | 57/125 [00:17<00:20,  3.37batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  46%|████▋     | 58/125 [00:17<00:20,  3.34batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  47%|████▋     | 59/125 [00:17<00:20,  3.28batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  48%|████▊     | 60/125 [00:18<00:20,  3.13batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  49%|████▉     | 61/125 [00:18<00:20,  3.20batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  50%|████▉     | 62/125 [00:18<00:19,  3.18batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  50%|█████     | 63/125 [00:19<00:20,  3.08batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  51%|█████     | 64/125 [00:19<00:19,  3.16batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  52%|█████▏    | 65/125 [00:19<00:18,  3.25batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  53%|█████▎    | 66/125 [00:19<00:18,  3.23batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  54%|█████▎    | 67/125 [00:20<00:18,  3.06batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  54%|█████▍    | 68/125 [00:20<00:18,  3.07batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  55%|█████▌    | 69/125 [00:20<00:17,  3.18batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  56%|█████▌    | 70/125 [00:21<00:18,  3.00batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  57%|█████▋    | 71/125 [00:21<00:16,  3.22batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  58%|█████▊    | 72/125 [00:21<00:18,  2.94batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  58%|█████▊    | 73/125 [00:22<00:17,  2.98batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  59%|█████▉    | 74/125 [00:22<00:16,  3.10batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  60%|██████    | 75/125 [00:22<00:15,  3.18batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  61%|██████    | 76/125 [00:23<00:15,  3.17batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  62%|██████▏   | 77/125 [00:23<00:15,  3.11batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  62%|██████▏   | 78/125 [00:23<00:14,  3.28batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  63%|██████▎   | 79/125 [00:24<00:13,  3.32batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  64%|██████▍   | 80/125 [00:24<00:15,  2.95batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  65%|██████▍   | 81/125 [00:24<00:14,  3.07batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  66%|██████▌   | 82/125 [00:25<00:14,  3.00batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  66%|██████▋   | 83/125 [00:25<00:16,  2.62batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  67%|██████▋   | 84/125 [00:25<00:14,  2.81batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  68%|██████▊   | 85/125 [00:26<00:12,  3.15batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  69%|██████▉   | 86/125 [00:26<00:13,  2.90batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  70%|██████▉   | 87/125 [00:26<00:12,  3.15batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  70%|███████   | 88/125 [00:27<00:11,  3.19batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  71%|███████   | 89/125 [00:27<00:11,  3.16batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  72%|███████▏  | 90/125 [00:27<00:10,  3.21batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  73%|███████▎  | 91/125 [00:28<00:09,  3.42batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  74%|███████▎  | 92/125 [00:28<00:09,  3.43batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  74%|███████▍  | 93/125 [00:28<00:09,  3.29batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  75%|███████▌  | 94/125 [00:28<00:09,  3.25batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  76%|███████▌  | 95/125 [00:29<00:10,  2.95batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  77%|███████▋  | 96/125 [00:29<00:09,  3.20batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  78%|███████▊  | 97/125 [00:29<00:09,  3.11batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  78%|███████▊  | 98/125 [00:30<00:08,  3.20batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  79%|███████▉  | 99/125 [00:30<00:08,  3.05batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  80%|████████  | 100/125 [00:30<00:08,  2.99batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  81%|████████  | 101/125 [00:31<00:08,  2.93batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  82%|████████▏ | 102/125 [00:31<00:07,  3.07batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  82%|████████▏ | 103/125 [00:31<00:07,  3.03batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  83%|████████▎ | 104/125 [00:32<00:06,  3.18batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  84%|████████▍ | 105/125 [00:32<00:05,  3.37batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  85%|████████▍ | 106/125 [00:32<00:05,  3.48batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  86%|████████▌ | 107/125 [00:33<00:05,  3.34batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  86%|████████▋ | 108/125 [00:33<00:05,  3.15batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  87%|████████▋ | 109/125 [00:33<00:04,  3.27batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  88%|████████▊ | 110/125 [00:34<00:04,  3.27batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  89%|████████▉ | 111/125 [00:34<00:04,  3.23batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  90%|████████▉ | 112/125 [00:34<00:04,  3.13batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  90%|█████████ | 113/125 [00:34<00:03,  3.26batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  91%|█████████ | 114/125 [00:35<00:03,  3.03batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  92%|█████████▏| 115/125 [00:35<00:03,  3.01batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  93%|█████████▎| 116/125 [00:36<00:03,  2.96batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  94%|█████████▎| 117/125 [00:36<00:02,  2.70batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  94%|█████████▍| 118/125 [00:36<00:02,  2.89batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  95%|█████████▌| 119/125 [00:37<00:01,  3.02batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  96%|█████████▌| 120/125 [00:37<00:01,  3.04batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  97%|█████████▋| 121/125 [00:37<00:01,  3.23batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  98%|█████████▊| 122/125 [00:38<00:01,  2.83batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  98%|█████████▊| 123/125 [00:38<00:00,  2.90batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches:  99%|█████████▉| 124/125 [00:38<00:00,  3.15batch/s]\u001b[A\u001b[A\n",
      "\n",
      "Validation Batches: 100%|██████████| 125/125 [00:38<00:00,  3.80batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Batches:  14%|█▍        | 101/704 [11:30<2:59:50, 17.89s/batch]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/2], Step: [101/704], Average MSE: 140868.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches:  14%|█▍        | 102/704 [11:44<2:47:04, 16.65s/batch]\u001b[A\n",
      "Batches:  15%|█▍        | 103/704 [11:49<2:12:09, 13.19s/batch]\u001b[A\n",
      "Batches:  15%|█▍        | 104/704 [11:54<1:45:52, 10.59s/batch]\u001b[A\n",
      "Batches:  15%|█▍        | 105/704 [11:58<1:28:09,  8.83s/batch]\u001b[A\n",
      "Batches:  15%|█▌        | 106/704 [12:11<1:39:22,  9.97s/batch]\u001b[A\n",
      "Batches:  15%|█▌        | 107/704 [12:17<1:27:24,  8.79s/batch]\u001b[A\n",
      "Batches:  15%|█▌        | 108/704 [12:22<1:15:55,  7.64s/batch]\u001b[A\n",
      "Batches:  15%|█▌        | 109/704 [12:27<1:06:32,  6.71s/batch]\u001b[A\n",
      "Batches:  16%|█▌        | 110/704 [12:37<1:16:38,  7.74s/batch]\u001b[A\n",
      "Batches:  16%|█▌        | 111/704 [12:45<1:19:04,  8.00s/batch]\u001b[A\n",
      "Batches:  16%|█▌        | 112/704 [12:52<1:15:51,  7.69s/batch]\u001b[A\n",
      "Batches:  16%|█▌        | 113/704 [13:01<1:19:15,  8.05s/batch]\u001b[A\n",
      "Batches:  16%|█▌        | 114/704 [13:14<1:32:13,  9.38s/batch]\u001b[A\n",
      "Batches:  16%|█▋        | 115/704 [13:19<1:19:32,  8.10s/batch]\u001b[A\n",
      "Batches:  16%|█▋        | 116/704 [13:23<1:07:28,  6.88s/batch]\u001b[A\n",
      "Batches:  17%|█▋        | 117/704 [13:28<1:02:38,  6.40s/batch]\u001b[A\n",
      "Batches:  17%|█▋        | 118/704 [13:34<1:00:12,  6.16s/batch]\u001b[A\n",
      "Batches:  17%|█▋        | 119/704 [13:43<1:09:44,  7.15s/batch]\u001b[A\n",
      "Batches:  17%|█▋        | 120/704 [13:49<1:04:45,  6.65s/batch]\u001b[A\n",
      "Batches:  17%|█▋        | 121/704 [13:57<1:09:53,  7.19s/batch]\u001b[A\n",
      "Batches:  17%|█▋        | 122/704 [14:03<1:05:54,  6.79s/batch]\u001b[A\n",
      "Batches:  17%|█▋        | 123/704 [14:12<1:11:49,  7.42s/batch]\u001b[A\n",
      "Batches:  18%|█▊        | 124/704 [14:17<1:05:09,  6.74s/batch]\u001b[A\n",
      "Batches:  18%|█▊        | 125/704 [14:23<1:03:30,  6.58s/batch]\u001b[A\n",
      "Batches:  18%|█▊        | 126/704 [14:30<1:02:44,  6.51s/batch]\u001b[A\n",
      "Batches:  18%|█▊        | 127/704 [14:36<1:03:20,  6.59s/batch]\u001b[A\n",
      "Batches:  18%|█▊        | 128/704 [14:44<1:05:59,  6.87s/batch]\u001b[A\n",
      "Batches:  18%|█▊        | 129/704 [14:49<1:01:24,  6.41s/batch]\u001b[A\n",
      "Batches:  18%|█▊        | 130/704 [14:55<1:00:23,  6.31s/batch]\u001b[A\n",
      "Batches:  19%|█▊        | 131/704 [15:01<58:22,  6.11s/batch]  \u001b[A\n",
      "Batches:  19%|█▉        | 132/704 [15:06<56:30,  5.93s/batch]\u001b[A\n",
      "Batches:  19%|█▉        | 133/704 [15:13<57:58,  6.09s/batch]\u001b[A\n",
      "Batches:  19%|█▉        | 134/704 [15:25<1:14:02,  7.79s/batch]\u001b[A\n",
      "Batches:  19%|█▉        | 135/704 [15:30<1:05:52,  6.95s/batch]\u001b[A\n",
      "Batches:  19%|█▉        | 136/704 [15:34<58:25,  6.17s/batch]  \u001b[A\n",
      "Batches:  19%|█▉        | 137/704 [15:38<51:33,  5.46s/batch]\u001b[A\n",
      "Batches:  20%|█▉        | 138/704 [15:43<49:57,  5.30s/batch]\u001b[A\n",
      "Batches:  20%|█▉        | 139/704 [15:50<56:36,  6.01s/batch]\u001b[A\n",
      "Batches:  20%|█▉        | 140/704 [15:55<52:29,  5.58s/batch]\u001b[A\n",
      "Batches:  20%|██        | 141/704 [16:01<53:38,  5.72s/batch]\u001b[A\n",
      "Batches:  20%|██        | 142/704 [16:12<1:07:42,  7.23s/batch]\u001b[A\n",
      "Batches:  20%|██        | 143/704 [16:25<1:25:00,  9.09s/batch]\u001b[A\n",
      "Batches:  20%|██        | 144/704 [16:30<1:12:51,  7.81s/batch]\u001b[A\n",
      "Batches:  21%|██        | 145/704 [16:37<1:09:00,  7.41s/batch]\u001b[A\n",
      "Batches:  21%|██        | 146/704 [16:43<1:06:49,  7.19s/batch]\u001b[A\n",
      "Batches:  21%|██        | 147/704 [16:55<1:19:10,  8.53s/batch]\u001b[A"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc = \"Training Epochs\", unit = \"epoch\"):\n",
    "    for i, (data, lengths, labels) in enumerate(tqdm(train_loader, desc = \"Batches\", unit = \"batch\")):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(data, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Average MSE: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
